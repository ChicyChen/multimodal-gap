{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize COCO features\n",
    "\n",
    "1. visualize coco features\n",
    "2. identify pca-one; what is its cosine similarity with the residual (should be very high)\n",
    "3. move along the direction, plot 1-dim loss landscape. [-2,-1,-0.5,0,0.5,1,2]\n",
    "    - need to have a fn(scalar,), output loss. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "from enum import Enum\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import glob \n",
    "def my_norm(x):\n",
    "    return x/np.linalg.norm(x, axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_list = list()\n",
    "\n",
    "for pickle_path in glob.glob('./features*/feature_dump_*.pkl'):\n",
    "    with open(pickle_path, 'rb') as pkl_file:\n",
    "        data_dict = pickle.load(pkl_file)\n",
    "        assert len(data_dict['clip_image_features_list']) == len(data_dict['clip_text_features_list'])\n",
    "        # assert len(data_dict['clip_image_features_list']) == len(data_dict['target_image_features_list'])\n",
    "        # print('Number of image-text pairs', len(data_dict['clip_image_features_list']))\n",
    "        data_dict_list.append(data_dict)\n",
    "\n",
    "print('Number of experiment files loaded', len(data_dict_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "# from sklearn.decomposition import TruncatedSVD as PCA # showns as multiple lines. \n",
    "# from sklearn.manifold import TSNE as PCA # \n",
    "# import umap\n",
    "# from umap import UMAP as PCA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# sns.set(font_scale=2)  # crazy big\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "sns.set_theme()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functionality: given a list of exp, plot one modality. \n",
    "sns.set_context(\"talk\", font_scale=1.5) # paper, notebook, talk, and poster; font_scale=1.5,\n",
    "\n",
    "def plot_scattered_cones(data_dict_list, modality_str, draw=True):\n",
    "    assert modality_str in ['clip_image_features_list', 'clip_text_features_list', 'target_image_features_list']\n",
    "    print('modality_str: ', modality_str)\n",
    "    # dataset_size = len(data_dict_list[0][modality_str])\n",
    "    dataset_size = 5000\n",
    "\n",
    "    total_feature_list = list()\n",
    "    label_list = list()\n",
    "    for expriment_idx in range(len(data_dict_list)):\n",
    "        total_feature_list.append(data_dict_list[expriment_idx][modality_str][:dataset_size])\n",
    "        label_list.extend(['Random-{}'.format(expriment_idx+1)] * dataset_size)\n",
    "    total_feature_np = np.concatenate(total_feature_list, axis=0) \n",
    "    total_feature_np = my_norm(total_feature_np) # L2-normalize\n",
    "    assert len(total_feature_np) == len(data_dict_list) * dataset_size\n",
    "\n",
    "    pca = PCA(n_components=6)\n",
    "    pca_result = pca.fit_transform(total_feature_np)\n",
    "    print('pca.explained_variance_ratio_', pca.explained_variance_ratio_)\n",
    "    print('pca.singular_values_', pca.singular_values_)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['pca_one'] = pca_result[:,0]\n",
    "    df['pca_two'] = pca_result[:,1] \n",
    "    df['Random Seed'] = label_list\n",
    "\n",
    "    if draw:\n",
    "        plt.figure(figsize=(20.0,6.18 * 2))\n",
    "        p1 = sns.scatterplot(\n",
    "            x=\"pca_one\", y=\"pca_two\",\n",
    "            hue=\"Random Seed\",\n",
    "            data=df,\n",
    "            legend=True,\n",
    "        )\n",
    "        plt.xlabel(\"\")\n",
    "        plt.ylabel(\"\")\n",
    "        plt.legend(title='Random Seed', loc='upper left', bbox_to_anchor=(1.00, 1.0, ), prop={'size': 18})\n",
    "        plt.show()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clip_img = plot_scattered_cones(data_dict_list[:25], 'clip_image_features_list',   draw=True)\n",
    "df_clip_txt = plot_scattered_cones(data_dict_list[:25], 'clip_text_features_list',    draw=True)\n",
    "df_resnet   = plot_scattered_cones(data_dict_list[:25], 'target_image_features_list', draw=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_df(df):\n",
    "    plt.figure(figsize=(20.0,6.18 * 2))\n",
    "    df['Seed'] = df['Random Seed'].str.replace('Random-', '', regex=False)\n",
    "    p1 = sns.scatterplot(\n",
    "        x=\"pca_one\", y=\"pca_two\",\n",
    "        hue=\"Seed\",\n",
    "        data=df,\n",
    "        legend=True,\n",
    "    )\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.legend(title='Random Seed', loc='upper left', bbox_to_anchor=(1.00, 1.0, ), ncol=2) # prop={'size': 50}, \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "draw_df(df_clip_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot PCA Singular Values, Explained Variance Ratios. \n",
    "Kind of anwering Mert's question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modality_str:  clip_image_features_list\n",
      "pca.explained_variance_ratio_\n",
      "0.043, 0.041, 0.039, 0.038, 0.036, 0.035, 0.035, 0.034, 0.033, 0.032, \n",
      "pca.singular_values_ [72.44832  70.31703  68.78217  68.24517  66.22955  65.66144  65.02128\n",
      " 64.06602  63.149437 62.50923  61.43108  60.71535  60.435135 59.02705\n",
      " 58.74808  57.4058   56.325825 56.2117   55.202732 54.309063 53.766792\n",
      " 52.040756 51.68926  49.76612  34.14688  33.398888 32.901985 31.960554\n",
      " 31.528515 31.300081 30.672626 30.518982 30.29744  29.762638 29.396282\n",
      " 28.373528 28.064127 27.74946  27.346584 27.130186 26.959745 26.397924\n",
      " 25.524904 25.109116 24.717733 24.531994 24.060846 23.81253  22.803596\n",
      " 20.144312]\n",
      "modality_str:  clip_text_features_list\n",
      "pca.explained_variance_ratio_\n",
      "0.043, 0.041, 0.039, 0.037, 0.037, 0.035, 0.034, 0.033, 0.033, 0.031, \n",
      "pca.singular_values_ [71.93895  70.64999  68.51955  67.25281  66.71326  65.2795   64.50423\n",
      " 63.39669  62.925117 61.176167 59.73097  58.7134   58.423645 57.11752\n",
      " 56.474472 55.85696  54.98844  54.659405 54.08874  53.35901  51.593594\n",
      " 50.34826  49.43106  48.493847 16.067904 15.492056 15.30791  14.992251\n",
      " 14.946433 14.73657  14.656306 14.519942 14.41191  14.366245 14.130468\n",
      " 14.007584 13.708626 13.655253 13.45591  13.389069 13.198088 13.179104\n",
      " 13.093057 12.848161 12.838188 12.79897  12.603904 12.445068 12.337545\n",
      " 12.306129]\n",
      "modality_str:  target_image_features_list\n",
      "pca.explained_variance_ratio_\n",
      "0.056, 0.055, 0.054, 0.051, 0.050, 0.050, 0.049, 0.046, 0.044, 0.043, \n",
      "pca.singular_values_ [57.44344   56.822586  56.4279    54.55056   54.171036  53.912224\n",
      " 53.301693  51.85659   50.885063  50.07982   49.386353  49.12857\n",
      " 48.405567  47.63106   47.15982   45.581974  45.29316   45.029636\n",
      " 44.288643  43.610165  42.718163  41.86789   40.769337  39.61369\n",
      "  4.8666005  4.7441974  4.5143256  4.4266877  4.175692   4.155532\n",
      "  4.1449823  4.055484   3.8198297  3.783392   3.687432   3.661967\n",
      "  3.6238446  3.5420978  3.483381   3.4556499  3.2627327  3.2502015\n",
      "  3.1480756  3.124066   3.0445938  2.9486566  2.828199   2.759845\n",
      "  2.7152538  2.6587367]\n"
     ]
    }
   ],
   "source": [
    "# Functionality: given a list of exp, plot one modality. \n",
    "sns.set_context(\"talk\", font_scale=1.5) # paper, notebook, talk, and poster; font_scale=1.5,\n",
    "\n",
    "def plot_pca_stats(data_dict_list, modality_str, draw=True):\n",
    "    assert modality_str in ['clip_image_features_list', 'clip_text_features_list', 'target_image_features_list']\n",
    "    print('modality_str: ', modality_str)\n",
    "    # dataset_size = len(data_dict_list[0][modality_str])\n",
    "    dataset_size = 5000\n",
    "\n",
    "    total_feature_list = list()\n",
    "    label_list = list()\n",
    "    for expriment_idx in range(len(data_dict_list)):\n",
    "        total_feature_list.append(data_dict_list[expriment_idx][modality_str][:dataset_size])\n",
    "        label_list.extend(['Random-{}'.format(expriment_idx+1)] * dataset_size)\n",
    "    total_feature_np = np.concatenate(total_feature_list, axis=0) \n",
    "    total_feature_np = my_norm(total_feature_np) # L2-normalize\n",
    "    assert len(total_feature_np) == len(data_dict_list) * dataset_size\n",
    "\n",
    "    pca = PCA(n_components=50)\n",
    "    pca_result = pca.fit_transform(total_feature_np)\n",
    "    print('pca.explained_variance_ratio_')\n",
    "    for ratio in pca.explained_variance_ratio_[:10]:\n",
    "        print('{:.3f},'.format(ratio), end=' ')\n",
    "    print()\n",
    "\n",
    "\n",
    "    print('pca.singular_values_', pca.singular_values_)\n",
    "    return\n",
    "\n",
    "\n",
    "df_clip_img = plot_pca_stats(data_dict_list[:25], 'clip_image_features_list',   draw=True)\n",
    "df_clip_txt = plot_pca_stats(data_dict_list[:25], 'clip_text_features_list',    draw=True)\n",
    "df_resnet   = plot_pca_stats(data_dict_list[:25], 'target_image_features_list', draw=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "09c077faaa20da841f22e0f4d12b4addb73e00d9291bc78d00732f9f39794f23"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('clip')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
